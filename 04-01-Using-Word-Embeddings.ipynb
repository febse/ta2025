{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f540b577",
   "metadata": {},
   "source": [
    "## Using Word Embeddings\n",
    "\n",
    "In the previous sections, we have built a Word2Vec model from scratch using NumPy. Now, let's see how we can use the learned word embeddings for various NLP tasks with the focus on sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012e25fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./.venv/lib/python3.13/site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./.venv/lib/python3.13/site-packages (from gensim) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in ./.venv/lib/python3.13/site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in ./.venv/lib/python3.13/site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.13/site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Download the pretrained Word2Vec vectors (GoogleNews-vectors-negative300)\n",
    "word2vec_model = api.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa2dc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I really liked this Summerslam due to the look...  positive\n",
       "1  Not many television shows appeal to quite as m...  positive\n",
       "2  The film quickly gets to a major chase scene w...  negative\n",
       "3  Jane Austen would definitely approve of this o...  positive\n",
       "4  Expectations were somewhat high for me when I ...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://github.com/febse/data/raw/refs/heads/main/ta/IMDB-Dataset-5000.csv.zip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c8d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def document_embedding(text, model):\n",
    "    words = [w for w in text.split() if w in model]\n",
    "    if words:\n",
    "        return np.mean([model[w] for w in words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "df['avg_word'] = df['review'].apply(lambda x: document_embedding(x, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ac90ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.026841605, 0.044992644, 0.017120501, 0.0777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.044581123, 0.025324179, 0.020859266, 0.0939...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.04855869, 0.031639244, 0.0031714232, 0.0996...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.03325866, 0.024321612, -0.0009411083, 0.060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.056710232, 0.029389769, 0.031232158, 0.0919...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I really liked this Summerslam due to the look...  positive   \n",
       "1  Not many television shows appeal to quite as m...  positive   \n",
       "2  The film quickly gets to a major chase scene w...  negative   \n",
       "3  Jane Austen would definitely approve of this o...  positive   \n",
       "4  Expectations were somewhat high for me when I ...  negative   \n",
       "\n",
       "                                            avg_word  \n",
       "0  [0.026841605, 0.044992644, 0.017120501, 0.0777...  \n",
       "1  [0.044581123, 0.025324179, 0.020859266, 0.0939...  \n",
       "2  [0.04855869, 0.031639244, 0.0031714232, 0.0996...  \n",
       "3  [0.03325866, 0.024321612, -0.0009411083, 0.060...  \n",
       "4  [0.056710232, 0.029389769, 0.031232158, 0.0919...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e286ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert avg_word column to numpy array\n",
    "X = np.vstack(df['avg_word'].values)\n",
    "y = df['sentiment'].map({'positive': 1, 'negative': 0}).values\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158838c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38030644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02684161,  0.04499264,  0.0171205 , ..., -0.06149487,\n",
       "         0.02433256, -0.02856859],\n",
       "       [ 0.04458112,  0.02532418,  0.02085927, ..., -0.01347773,\n",
       "         0.03515555, -0.0291379 ],\n",
       "       [ 0.04855869,  0.03163924,  0.00317142, ..., -0.05177125,\n",
       "         0.04260951, -0.02817884],\n",
       "       [ 0.03325866,  0.02432161, -0.00094111, ..., -0.06046228,\n",
       "         0.06452684, -0.00596103],\n",
       "       [ 0.05671023,  0.02938977,  0.03123216, ..., -0.03327884,\n",
       "         0.05188526, -0.03141383]], shape=(5, 300), dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a070de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ac580",
   "metadata": {},
   "source": [
    "## Getting Document Vectors\n",
    "\n",
    "![Large Language Models](https://bea.stollnitz.com/images/gpt-transformer/3-transformer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6847a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(api_key=\"YOUR_OPENAI_API_KEY\")\n",
    "\n",
    "# def get_openai_embedding(text, model=\"text-embedding-3-small\"):\n",
    "#     \"\"\"\n",
    "#     Get embedding for a text using OpenAI's API (v1.0+ compatible).\n",
    "    \n",
    "#     Parameters:\n",
    "#     text (str): The text to embed\n",
    "#     model (str): The embedding model to use (default: \"text-embedding-3-small\")\n",
    "    \n",
    "#     Returns:\n",
    "#     list: The embedding vector\n",
    "#     \"\"\"\n",
    "#     response = client.embeddings.create(\n",
    "#         model=model,\n",
    "#         input=text\n",
    "#     )\n",
    "#     return response.data[0].embedding\n",
    "\n",
    "# # Download embeddings for each review (this may take time and cost money)\n",
    "# # Uncomment the line below to run (be aware of API costs)\n",
    "\n",
    "# get_openai_embedding(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11026029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_ollama_embedding(text, model=\"llama3.2:latest\"):\n",
    "    \"\"\"\n",
    "    Get embedding for a text using Ollama's local API.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The text to embed\n",
    "    model (str): The embedding model to use (default: \"nomic-embed-text\")\n",
    "\n",
    "    Returns:\n",
    "    list: The embedding vector\n",
    "    \"\"\"\n",
    "    url = \"http://localhost:11434/api/embeddings\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": text\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"embedding\"]\n",
    "\n",
    "# Example usage:\n",
    "len(get_ollama_embedding(\"Hello, world!\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
